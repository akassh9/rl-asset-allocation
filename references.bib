@article{kayaRegimesNonparametricIdentification2010,
  title = {Regimes: {{{\emph{Nonparametric Identification}}}}{\emph{ and }}{{{\emph{Forecasting}}}}},
  shorttitle = {Regimes},
  author = {Kaya, Hakan and Lee, Wai and Pornrojnangkool, Bobby},
  year = {2010},
  month = jan,
  journal = {The Journal of Portfolio Management},
  volume = {36},
  number = {2},
  pages = {94--105},
  issn = {0095-4918, 2168-8656},
  doi = {10.3905/JPM.2010.36.2.094},
  urldate = {2025-05-13},
  langid = {english},
  keywords = {Regime Detection},
  file = {/Users/akash009/Zotero/storage/AZAPXBEV/Kaya et al. - 2010 - Regimes Nonparametric Identification and Forecasting.pdf}
}

@misc{liuFinRLDeepReinforcement2022,
  title = {{{FinRL}}: {{A Deep Reinforcement Learning Library}} for {{Automated Stock Trading}} in {{Quantitative Finance}}},
  shorttitle = {{{FinRL}}},
  author = {Liu, Xiao-Yang and Yang, Hongyang and Chen, Qian and Zhang, Runjia and Yang, Liuqing and Xiao, Bowen and Wang, Christina Dan},
  year = {2022},
  month = mar,
  number = {arXiv:2011.09607},
  eprint = {2011.09607},
  primaryclass = {q-fin},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2011.09607},
  urldate = {2025-05-13},
  abstract = {As deep reinforcement learning (DRL) has been recognized as an effective approach in quantitative finance, getting hands-on experiences is attractive to beginners. However, to train a practical DRL trading agent that decides where to trade, at what price, and what quantity involves error-prone and arduous development and debugging. In this paper, we introduce a DRL library FinRL that facilitates beginners to expose themselves to quantitative finance and to develop their own stock trading strategies. Along with easily-reproducible tutorials, FinRL library allows users to streamline their own developments and to compare with existing schemes easily. Within FinRL, virtual environments are configured with stock market datasets, trading agents are trained with neural networks, and extensive backtesting is analyzed via trading performance. Moreover, it incorporates important trading constraints such as transaction cost, market liquidity and the investor's degree of risk-aversion. FinRL is featured with completeness, hands-on tutorial and reproducibility that favors beginners: (i) at multiple levels of time granularity, FinRL simulates trading environments across various stock markets, including NASDAQ-100, DJIA, S\&P 500, HSI, SSE 50, and CSI 300; (ii) organized in a layered architecture with modular structure, FinRL provides fine-tuned state-of-the-art DRL algorithms (DQN, DDPG, PPO, SAC, A2C, TD3, etc.), commonly-used reward functions and standard evaluation baselines to alleviate the debugging workloads and promote the reproducibility, and (iii) being highly extendable, FinRL reserves a complete set of user-import interfaces. Furthermore, we incorporated three application demonstrations, namely single stock trading, multiple stock trading, and portfolio allocation. The FinRL library will be available on Github at link https://github.com/AI4Finance-LLC/FinRL-Library.},
  archiveprefix = {arXiv},
  keywords = {ML Asset Allocation},
  file = {/Users/akash009/Zotero/storage/YJTLTXLH/Liu et al. - 2022 - FinRL A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance.pdf;/Users/akash009/Zotero/storage/DKBG4JDM/2011.html}
}

@misc{mullinerRegimes2025,
  type = {{{SSRN Scholarly Paper}}},
  title = {Regimes},
  author = {Mulliner, Amara and Harvey, Campbell R. and Xia, Chao and Fang, Ed and Van Hemert, Otto},
  year = {2025},
  month = mar,
  number = {5164863},
  eprint = {5164863},
  publisher = {Social Science Research Network},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.5164863},
  urldate = {2025-05-13},
  abstract = {We propose a new systematic method for detecting the current economic regime and show how to use this information for predicting returns. Rather than presupposing a set of possible regimes, we rely on economic state variables and determine for which historical dates the values of these variables were most similar. To establish our position in an asset today, we identify historically similar periods and measure subsequent performance of the asset. If the historical performance is positive, we initiate a long position; conversely, if it is negative, we initiate a short position. We illustrate the efficacy of our method on six common long-short equity factors over 1985-2024. Our results show that using this information our regime classification leads to significant outperformance. Interestingly, we also find important information in what we call anti-regimesperiods in the past that are the most dissimilar to today.},
  archiveprefix = {Social Science Research Network},
  langid = {english},
  keywords = {Regime Detection},
  file = {/Users/akash009/Zotero/storage/VMCKZ4AB/Mulliner et al. - 2025 - Regimes.pdf}
}

@misc{oliveiraTacticalAssetAllocation2025,
  title = {Tactical {{Asset Allocation}} with {{Macroeconomic Regime Detection}}},
  author = {Oliveira, Daniel Cunha and Sandfelder, Dylan and Fujita, Andr{\'e} and Dong, Xiaowen and Cucuringu, Mihai},
  year = {2025},
  month = mar,
  number = {arXiv:2503.11499},
  eprint = {2503.11499},
  primaryclass = {q-fin},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.11499},
  urldate = {2025-05-13},
  abstract = {This paper extends the tactical asset allocation literature by incorporating regime modeling using techniques from machine learning. We propose a novel model that classifies current regimes, forecasts the distribution of future regimes, and integrates these forecasts with the historical performance of individual assets to optimize portfolio allocations. Utilizing a macroeconomic data set from the FRED-MD database, our approach employs a modified k-means algorithm to ensure consistent regime classification over time. We then leverage these regime predictions to estimate expected returns and volatilities, which are subsequently mapped into portfolio allocations using various sizing schemes. Our method outperforms traditional benchmarks such as equal-weight, buy-and-hold, and random regime models. Additionally, we are the first to apply a regime detection model from a large macroeconomic dataset to tactical asset allocation, demonstrating significant improvements in portfolio performance. Our work presents several key contributions, including a novel data-driven regime detection algorithm tailored for uncertainty in forecasted regimes and applying the FRED-MD data set for tactical asset allocation.},
  archiveprefix = {arXiv},
  keywords = {ML Asset Allocation,Regime Detection},
  file = {/Users/akash009/Zotero/storage/HYWQ65HD/Oliveira et al. - 2025 - Tactical Asset Allocation with Macroeconomic Regime Detection.pdf;/Users/akash009/Zotero/storage/ZQCPG8KZ/2503.html}
}

@article{wangDeepTraderDeepReinforcement2021,
  title = {{{DeepTrader}}: {{A Deep Reinforcement Learning Approach}} for {{Risk-Return Balanced Portfolio Management}} with {{Market Conditions Embedding}}},
  shorttitle = {{{DeepTrader}}},
  author = {Wang, Zhicheng and Huang, Biwei and Tu, Shikui and Zhang, Kun and Xu, Lei},
  year = {2021},
  month = may,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {35},
  number = {1},
  pages = {643--650},
  issn = {2374-3468},
  doi = {10.1609/aaai.v35i1.16144},
  urldate = {2025-05-13},
  abstract = {Most existing reinforcement learning (RL)-based portfolio management models do not take into account the market conditions, which limits their performance in risk-return balancing. In this paper, we propose DeepTrader, a deep RL method to optimize the investment policy. In particular, to tackle the risk-return balancing problem, our model embeds macro market conditions as an indicator to dynamically adjust the proportion between long and short funds, to lower the risk of market fluctuations, with the negative maximum drawdown as the reward function. Additionally, the model involves a unit to evaluate individual assets, which learns dynamic patterns from historical data with the price rising rate as the reward function. Both temporal and spatial dependencies between assets are captured hierarchically by a specific type of graph structure. Particularly, we find that the estimated causal structure best captures the interrelationships between assets, compared to industry classification and correlation. The two units are complementary and integrated to generate a suitable portfolio which fits the market trend well and strikes a balance between return and risk effectively. Experiments on three well-known stock indexes demonstrate the superiority of DeepTrader in terms of risk-gain criteria.},
  copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  keywords = {Economic/Financial,ML Asset Allocation},
  file = {/Users/akash009/Zotero/storage/VU644QG9/Wang et al. - 2021 - DeepTrader A Deep Reinforcement Learning Approach for Risk-Return Balanced Portfolio Management wit.pdf}
}
